{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k_/917q0lsn2g199rm9y4s8jy5h0000gn/T/ipykernel_87437/1573589315.py:9: DtypeWarning: Columns (2,64,91,94,97,106,108,109,110,111,112,114,116,119,120,122,127,139,142,143,144,145,152,153,154,155,156,157,159,160,161,163,164,165,169,170,171,172,175,178,179,180,187,189,215,216,217,218,219,317,318) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(base_csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['func_stat_tcr'], dtype='object')\n",
      "[     nan 2.04e+03 2.07e+03 2.08e+03 9.96e+02 2.00e+00 2.09e+03 2.02e+03\n",
      " 2.06e+03 1.00e+00 2.03e+03 2.05e+03 9.98e+02 4.01e+03 2.01e+03 4.08e+03\n",
      " 3.00e+00 4.10e+03 4.05e+03 4.09e+03 4.03e+03 4.06e+03 4.02e+03 2.10e+03\n",
      " 4.07e+03 4.04e+03]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"../Data\"\n",
    "base_csv_path = os.path.join(base_dir, 'base.csv')\n",
    "assert os.path.exists(base_csv_path), f\"base {base_csv_path} does not exist\"\n",
    "\n",
    "output_csv_path = os.path.join(base_dir, 'm4_imputed.csv')\n",
    "df = pd.read_csv(base_csv_path)\n",
    "\n",
    "# print all columns containing word stat\n",
    "print(df.columns[df.columns.str.contains('func_stat_tcr')])\n",
    "# print unique values in init_stat\n",
    "print(df['func_stat_tcr'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace \"ethnicity\" has been replaced with ethcat variable\n",
    "desired_columns = ['thoracic_dgn', 'num_prev_tx', 'tah', 'vas', 'onvent', 'icu', 'inotropic', 'gender', 'abo',\n",
    "                   'wgt_kg_tcr', 'hgt_cm_tcr', 'education', 'ecmo_tcr', 'iabp_tcr', 'inotropes_tcr', 'func_stat_tcr',\n",
    "                   'diab', 'dial_ty_tcr', 'cereb_vasc', 'malig_tcr', 'most_rcnt_creat', 'tot_serum_album',\n",
    "                   'hemo_co_tcr', 'cig_use', 'prior_card_surg_tcr', 'histry_cig_old', 'init_stat', 'init_creat',\n",
    "                   'init_age', 'ethcat', 'init_hgt_cm_calc', 'init_wgt_kg_calc', 'ventilator_tcr', 'lvad_at_listing',\n",
    "                   'rvad_at_listing', 'work_income_tcr', 'academic_level_tcr', 'tx_date', 'init_date']\n",
    "\n",
    "df = df[desired_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed patients under 18: 10530/77410 (13.60% removed)\n"
     ]
    }
   ],
   "source": [
    "# Remove all init_age under 18\n",
    "pre_len = len(df.index)\n",
    "df = df[df['init_age'] >= 18]\n",
    "post_len = len(df.index)\n",
    "print(f\"Removed patients under 18: {pre_len - post_len}/{pre_len} ({(pre_len - post_len) / pre_len * 100:.2f}% removed)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with value 6 in ethcat before replacing values: 450\n",
      "Number of rows with value 6 in ethcat after replacing values: 1854\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of rows with value 6 in ethcat before replacing values: {len(df[df[\"ethcat\"] == 6])}')\n",
    "\n",
    "#1=1 (White), 2=2 (Black), 4=4 (Hispanic), 5=5 (Asian),6=6 (tidigare Amer Ind/Alaskan, kodas nu om till Other) 7=6 (tidigare Native Hawaiian, nu Other) 9=6 (tidigare Multiracial, nu Other)\n",
    "df['ethcat'] = df['ethcat'].replace([7, 9, 998], 6)\n",
    "\n",
    "print(f'Number of rows with value 6 in ethcat after replacing values: {len(df[df[\"ethcat\"] == 6])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Encode education\n",
    "\n",
    "df['education'] = df['education'].replace([2, 3], 1) # High school or less\n",
    "df['education'] = df['education'].replace([4], 2) # Some college\n",
    "df['education'] = df['education'].replace([5, 6], 3) # College or graduate\n",
    "df['education'] = df['education'].replace([996, 998], None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['func_stat_tcr', 'init_stat'], dtype='object')\n",
      "[ 1.  3.  2.  4. nan]\n"
     ]
    }
   ],
   "source": [
    "# Encode init_stat: label define status 1 \"Status 1A\" 2 \"Status 1B\" 3 \"Status 2\" 4 \"Temp inactive\"\n",
    "\n",
    "df[\"init_stat\"] = df[\"init_stat\"].replace([2010, 2110, 2120, 2130, 2090], 1)\n",
    "df[\"init_stat\"] = df[\"init_stat\"].replace([2020, 2140], 2)\n",
    "df[\"init_stat\"] = df[\"init_stat\"].replace([2030, 2150, 2160], 3)\n",
    "df[\"init_stat\"] = df[\"init_stat\"].replace([2999], 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Encode thoracic_dgn: label define diag 1 \"Cardiomyopathy\" 2 \"CAD\" 3 \"Valvular heart disease\" 4 \"Graft failure\" 5 \"Congenital\" 7 \"Other\"\n",
    "df[\"thoracic_dgn\"] = df[\"thoracic_dgn\"].replace(range(1000, 1099), 1)\n",
    "df[\"thoracic_dgn\"] = df[\"thoracic_dgn\"].replace([1201], 1)\n",
    "\n",
    "df[\"thoracic_dgn\"] = df[\"thoracic_dgn\"].replace([1007, 1200], 2)\n",
    "\n",
    "df[\"thoracic_dgn\"] = df[\"thoracic_dgn\"].replace([1202], 3)\n",
    "\n",
    "df[\"thoracic_dgn\"] = df[\"thoracic_dgn\"].replace(range(1100, 1199), 4)\n",
    "\n",
    "df[\"thoracic_dgn\"] = df[\"thoracic_dgn\"].replace(range(1203, 1207), 5)\n",
    "\n",
    "df[\"thoracic_dgn\"] = df[\"thoracic_dgn\"].replace([1208, 1209, 999, 1497, 1498], 7)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to only transplanted patients: 77410/120264 (64.37% remaining)\n",
      "Mean waitlist time: 78.00 days\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with no transplant date\n",
    "pre_len = len(df.index)\n",
    "df = df[df['tx_date'].notna()]\n",
    "post_len = len(df.index)\n",
    "\n",
    "print(f\"Filtered to only transplanted patients: {post_len}/{pre_len} ({post_len / pre_len * 100:.2f}% remaining)\")\n",
    "\n",
    "# Compute the time to transplant (waitlist time -> wl_time)\n",
    "df['wl_time'] = (\n",
    "        pd.to_datetime(df['tx_date'], format='%d%b%Y') - pd.to_datetime(df['init_date'], format='%d%b%Y')).dt.days\n",
    "df = df.drop(columns=['tx_date', 'init_date'])\n",
    "print(f\"Mean waitlist time: {df['wl_time'].median():.2f} days\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns with all missing values: 1/38 (2.63% removed)\n",
      "Removed columns with no variance: 2/37 (5.41% removed)\n"
     ]
    }
   ],
   "source": [
    "# Remove columns where all values are missing\n",
    "pre_len = len(df.columns)\n",
    "df = df.dropna(axis=1, how='all')\n",
    "post_len = len(df.columns)\n",
    "print(\n",
    "    f\"Removed columns with all missing values: {pre_len - post_len}/{pre_len} ({(pre_len - post_len) / pre_len * 100:.2f}% removed)\")\n",
    "\n",
    "# Remove columns where there is no variance\n",
    "pre_len = len(df.columns)\n",
    "df = df.loc[:, df.nunique() != 1]\n",
    "post_len = len(df.columns)\n",
    "print(\n",
    "    f\"Removed columns with no variance: {pre_len - post_len}/{pre_len} ({(pre_len - post_len) / pre_len * 100:.2f}% removed)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates \n",
    "output_csv_path_cleaned = os.path.join(base_dir, 'base_cleaned.csv')\n",
    "df.to_csv(output_csv_path_cleaned, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical columns: 24\n",
      "Categorical columns: ['num_prev_tx', 'tah', 'vas', 'onvent', 'icu', 'inotropic', 'gender', 'abo', 'education', 'ecmo_tcr', 'iabp_tcr', 'inotropes_tcr', 'diab', 'dial_ty_tcr', 'cereb_vasc', 'malig_tcr', 'cig_use', 'prior_card_surg_tcr', 'histry_cig_old', 'init_stat', 'ethcat', 'ventilator_tcr', 'work_income_tcr', 'academic_level_tcr']\n"
     ]
    }
   ],
   "source": [
    "# Find the categorical columns using nunique\n",
    "categorical_columns = df.nunique()[df.nunique() < 10].index.tolist()\n",
    "categorical_column_indexes = [df.columns.get_loc(c) for c in categorical_columns if c in df]\n",
    "\n",
    "# Print the number of categorical columns\n",
    "print(f\"Number of categorical columns: {len(categorical_columns)}\")\n",
    "print(f\"Categorical columns: {categorical_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from missingpy import MissForest\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "# Encode the categorical columns\n",
    "df[categorical_columns] = ordinal_encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "imputer = MissForest()\n",
    "\n",
    "wl_time = df.pop('wl_time')\n",
    "\n",
    "df = pd.DataFrame(imputer.fit_transform(df, cat_vars=categorical_column_indexes), columns=df.columns)\n",
    "\n",
    "df['wl_time'] = wl_time.values\n",
    "\n",
    "df[categorical_columns] = ordinal_encoder.inverse_transform(df[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=categorical_columns)\n",
    "df.to_csv(output_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
