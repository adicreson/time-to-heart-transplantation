{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../Data/model_0_selected.csv\") #Choose correct path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean waiting list time: 0.29\n",
      "0    0.71\n",
      "1    0.29\n",
      "Name: wl_time, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_wl_time = df['wl_time'].mean()\n",
    "print(f\"Mean waiting list time: {mean_wl_time}\")\n",
    "\n",
    "df['wl_time'] = df['wl_time'].apply(lambda x: 0 if x < mean_wl_time else 1)\n",
    "print(df['wl_time'].value_counts(normalize=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score post feature selection: 0.4814263953973475\n",
      "F1 macro score post feature selection: 0.6608490846259415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[329,  26],\n",
       "       [ 76,  69]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Keep first 500 rows for faster processing\n",
    "# df = df[:500]\n",
    "\n",
    "\n",
    "X = df.drop(['wl_time'], axis=1) #Remember to also drop the features that we're not chosen in the feature selection\n",
    "y = df['wl_time']\n",
    "\n",
    "one_hot_cols = [col for col in df.columns if df[col].nunique() == 2]\n",
    "columns_to_scale = [col for col in X.columns if col not in one_hot_cols]\n",
    "# scale all columns except the one-hot encoded ones\n",
    "scaler = StandardScaler()\n",
    "X[columns_to_scale] = scaler.fit_transform(X[columns_to_scale])\n",
    "\n",
    "log = LogisticRegression(max_iter=1000)\n",
    "f1_scores = cross_val_score(log, X, y, cv=5, scoring='f1').mean()\n",
    "f1_macro_scores = cross_val_score(log, X, y, cv=5, scoring='f1_macro').mean()\n",
    "\n",
    "print(f\"F1 score post feature selection: {f1_scores}\")\n",
    "print(f\"F1 macro score post feature selection: {f1_macro_scores}\")\n",
    "\n",
    "# plot confusion matrix\n",
    "log.fit(X, y)\n",
    "y_pred = log.predict(X)\n",
    "confusion_matrix(y, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
