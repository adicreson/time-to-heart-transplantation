{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data_120294_2023-03-29_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean waiting list time: 192.52839426430694\n",
      "0    0.716807\n",
      "1    0.283193\n",
      "Name: wl_time, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_wl_time = df['wl_time'].mean()\n",
    "print(f\"Mean waiting list time: {mean_wl_time}\")\n",
    "\n",
    "df['wl_time'] = df['wl_time'].apply(lambda x: 0 if x < mean_wl_time else 1)\n",
    "print(df['wl_time'].value_counts(normalize=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial F1 score: 0.4207234479936403\n",
      "Initial F1 macro score: 0.6316114297647631\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[51243,  4245],\n       [14736,  7186]])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Keep first 500 rows for faster processing\n",
    "# df = df[:500]\n",
    "\n",
    "X = df.drop(['wl_time'], axis=1)\n",
    "y = df['wl_time']\n",
    "\n",
    "one_hot_cols = [col for col in df.columns if df[col].nunique() == 2]\n",
    "columns_to_scale = [col for col in X.columns if col not in one_hot_cols]\n",
    "# scale all columns except the one-hot encoded ones\n",
    "scaler = StandardScaler()\n",
    "X[columns_to_scale] = scaler.fit_transform(X[columns_to_scale])\n",
    "\n",
    "log = LogisticRegression(max_iter=1000)\n",
    "f1_scores = cross_val_score(log, X, y, cv=5, scoring='f1').mean()\n",
    "f1_macro_scores = cross_val_score(log, X, y, cv=5, scoring='f1_macro').mean()\n",
    "\n",
    "print(f\"Initial F1 score: {f1_scores}\")\n",
    "print(f\"Initial F1 macro score: {f1_macro_scores}\")\n",
    "\n",
    "# plot confusion matrix\n",
    "log.fit(X, y)\n",
    "y_pred = log.predict(X)\n",
    "confusion_matrix(y, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Num of features: 82\n",
      "Num of features recommended after feature selection: 79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "import numpy as np\n",
    "#Check if X contains wl_time column\n",
    "if 'wl_time' in X.columns:\n",
    "    print(\"X contains wl_time column\")\n",
    "\n",
    "selector = RFECV(estimator=log, cv=5, scoring='f1', verbose=1)\n",
    "selector.fit(X, y)\n",
    "\n",
    "print(f\"Num of features: {X.shape[1]}\")\n",
    "print(f\"Num of features recommended after feature selection: {selector.n_features_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: thoracic_dgn, Ranking: 1, Support: True\n",
      "Feature: wgt_kg_tcr, Ranking: 1, Support: True\n",
      "Feature: hgt_cm_tcr, Ranking: 1, Support: True\n",
      "Feature: func_stat_tcr, Ranking: 1, Support: True\n",
      "Feature: most_rcnt_creat, Ranking: 1, Support: True\n",
      "Feature: tot_serum_album, Ranking: 1, Support: True\n",
      "Feature: hemo_co_tcr, Ranking: 1, Support: True\n",
      "Feature: init_stat, Ranking: 1, Support: True\n",
      "Feature: init_age, Ranking: 1, Support: True\n",
      "Feature: init_hgt_cm_calc, Ranking: 1, Support: True\n",
      "Feature: init_wgt_kg_calc, Ranking: 1, Support: True\n",
      "Feature: wl_time, Ranking: 1, Support: True\n",
      "Feature: tah_N, Ranking: 1, Support: True\n",
      "Feature: tah_Y, Ranking: 1, Support: True\n",
      "Feature: vas_N, Ranking: 1, Support: True\n",
      "Feature: vas_Y, Ranking: 1, Support: True\n",
      "Feature: onvent_N, Ranking: 1, Support: True\n",
      "Feature: onvent_Y, Ranking: 1, Support: True\n",
      "Feature: icu_N, Ranking: 1, Support: True\n",
      "Feature: icu_Y, Ranking: 1, Support: True\n",
      "Feature: inotropic_N, Ranking: 1, Support: True\n",
      "Feature: inotropic_Y, Ranking: 1, Support: True\n",
      "Feature: gender_F, Ranking: 1, Support: True\n",
      "Feature: gender_M, Ranking: 1, Support: True\n",
      "Feature: abo_A, Ranking: 1, Support: True\n",
      "Feature: abo_A1, Ranking: 1, Support: True\n",
      "Feature: abo_A1B, Ranking: 1, Support: True\n",
      "Feature: abo_A2, Ranking: 1, Support: True\n",
      "Feature: abo_A2B, Ranking: 1, Support: True\n",
      "Feature: abo_AB, Ranking: 1, Support: True\n",
      "Feature: abo_B, Ranking: 1, Support: True\n",
      "Feature: abo_O, Ranking: 1, Support: True\n",
      "Feature: education_1.0, Ranking: 1, Support: True\n",
      "Feature: education_2.0, Ranking: 1, Support: True\n",
      "Feature: education_3.0, Ranking: 1, Support: True\n",
      "Feature: education_4.0, Ranking: 1, Support: True\n",
      "Feature: education_5.0, Ranking: 1, Support: True\n",
      "Feature: education_6.0, Ranking: 1, Support: True\n",
      "Feature: education_998.0, Ranking: 1, Support: True\n",
      "Feature: ecmo_tcr_0, Ranking: 1, Support: True\n",
      "Feature: ecmo_tcr_1, Ranking: 1, Support: True\n",
      "Feature: iabp_tcr_0, Ranking: 1, Support: True\n",
      "Feature: iabp_tcr_1, Ranking: 1, Support: True\n",
      "Feature: inotropes_tcr_0, Ranking: 1, Support: True\n",
      "Feature: inotropes_tcr_1, Ranking: 1, Support: True\n",
      "Feature: diab_1.0, Ranking: 1, Support: True\n",
      "Feature: diab_2.0, Ranking: 1, Support: True\n",
      "Feature: diab_3.0, Ranking: 1, Support: True\n",
      "Feature: diab_4.0, Ranking: 1, Support: True\n",
      "Feature: diab_5.0, Ranking: 1, Support: True\n",
      "Feature: diab_998.0, Ranking: 1, Support: True\n",
      "Feature: dial_ty_tcr_1.0, Ranking: 1, Support: True\n",
      "Feature: dial_ty_tcr_2.0, Ranking: 1, Support: True\n",
      "Feature: dial_ty_tcr_3.0, Ranking: 1, Support: True\n",
      "Feature: dial_ty_tcr_998.0, Ranking: 1, Support: True\n",
      "Feature: cereb_vasc_N, Ranking: 1, Support: True\n",
      "Feature: cereb_vasc_U, Ranking: 1, Support: True\n",
      "Feature: cereb_vasc_Y, Ranking: 1, Support: True\n",
      "Feature: malig_tcr_N, Ranking: 1, Support: True\n",
      "Feature: malig_tcr_U, Ranking: 1, Support: True\n",
      "Feature: malig_tcr_Y, Ranking: 1, Support: True\n",
      "Feature: cig_use_N, Ranking: 1, Support: True\n",
      "Feature: cig_use_Y, Ranking: 1, Support: True\n",
      "Feature: prior_card_surg_tcr_N, Ranking: 1, Support: True\n",
      "Feature: prior_card_surg_tcr_Y, Ranking: 1, Support: True\n",
      "Feature: histry_cig_old_N, Ranking: 1, Support: True\n",
      "Feature: histry_cig_old_U, Ranking: 1, Support: True\n",
      "Feature: histry_cig_old_Y, Ranking: 1, Support: True\n",
      "Feature: ethnicity_0, Ranking: 1, Support: True\n",
      "Feature: ethnicity_1, Ranking: 1, Support: True\n",
      "Feature: ventilator_tcr_0, Ranking: 1, Support: True\n",
      "Feature: ventilator_tcr_1, Ranking: 1, Support: True\n",
      "Feature: work_income_tcr_N, Ranking: 1, Support: True\n",
      "Feature: work_income_tcr_U, Ranking: 1, Support: True\n",
      "Feature: work_income_tcr_Y, Ranking: 1, Support: True\n",
      "Feature: academic_level_tcr_1.0, Ranking: 1, Support: True\n",
      "Feature: academic_level_tcr_2.0, Ranking: 1, Support: True\n",
      "Feature: academic_level_tcr_3.0, Ranking: 1, Support: True\n",
      "Feature: academic_level_tcr_996.0, Ranking: 1, Support: True\n",
      "Feature: prior_card_surg_tcr_U, Ranking: 2, Support: False\n",
      "Feature: dial_ty_tcr_999.0, Ranking: 3, Support: False\n",
      "Feature: education_996.0, Ranking: 4, Support: False\n"
     ]
    }
   ],
   "source": [
    "feature_rankings = list(zip(df.columns, selector.ranking_, selector.support_))\n",
    "feature_rankings_sorted = sorted(feature_rankings, key=lambda x: x[1])\n",
    "for feature, ranking, support in feature_rankings_sorted:\n",
    "    print(f\"Feature: {feature}, Ranking: {ranking}, Support: {support}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of features in X_new: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score after feature selection: 0.4125324240393315\n",
      "f1_macro_scores after feature selection: 0.6261678303761762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Remove all features that don't have support\n",
    "X_new = df[[col for col in df.columns if col in X.columns[selector.support_]]]\n",
    "\n",
    "#Print number of features in X_new\n",
    "print(f\"Num of features in X_new: {X_new.shape[1]}\")\n",
    "\n",
    "#Print if X_new contains wl_time column\n",
    "if 'wl_time' in X_new.columns:\n",
    "    print(\"X_new contains wl_time column\")\n",
    "\n",
    "log = LogisticRegression(max_iter=1000)\n",
    "log.fit(X_new, y)\n",
    "\n",
    "# Perform k-fold cross-validation and compute the initial F1 score\n",
    "avg_score = cross_val_score(log, X_new, y, cv=5, scoring='f1').mean()\n",
    "avg_score_macro = cross_val_score(log, X_new, y, cv=5, scoring='f1_macro').mean()\n",
    "print(f\"F1_score after feature selection: {avg_score}\")\n",
    "print(f'f1_macro_scores after feature selection: {avg_score_macro}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: work_income_tcr_N, Weight: -0.9678089315509145\n",
      "Feature: abo_AB, Weight: -0.684179938805338\n",
      "Feature: inotropes_tcr_1, Weight: -0.5682821730319841\n",
      "Feature: academic_level_tcr_3.0, Weight: -0.5487430856844796\n",
      "Feature: education_996.0, Weight: -0.3393209865930409\n",
      "Feature: academic_level_tcr_998.0, Weight: -0.31957487361415887\n",
      "Feature: iabp_tcr_1, Weight: -0.29518645674106053\n",
      "Feature: inotropic_N, Weight: -0.28241325123497435\n",
      "Feature: tah_N, Weight: -0.23923932909024853\n",
      "Feature: dial_ty_tcr_1.0, Weight: -0.2300457286732634\n",
      "Feature: vas_N, Weight: -0.22789411492461137\n",
      "Feature: icu_N, Weight: -0.22476052437973923\n",
      "Feature: malig_tcr_N, Weight: -0.20660069321362803\n",
      "Feature: ventilator_tcr_1, Weight: -0.1892022310203656\n",
      "Feature: gender_F, Weight: -0.1883399258357557\n",
      "Feature: cig_use_N, Weight: -0.17431678726257402\n",
      "Feature: prior_card_surg_tcr_U, Weight: -0.16468900369117082\n",
      "Feature: ethnicity_1, Weight: -0.15846805195506433\n",
      "Feature: academic_level_tcr_1.0, Weight: -0.15822668093245973\n",
      "Feature: onvent_Y, Weight: -0.15349935384614288\n",
      "Feature: ecmo_tcr_0, Weight: -0.1470386213773639\n",
      "Feature: abo_B, Weight: -0.14533491985794125\n",
      "Feature: histry_cig_old_U, Weight: -0.14087807568398622\n",
      "Feature: prior_card_surg_tcr_N, Weight: -0.11370595893792071\n",
      "Feature: ecmo_tcr_1, Weight: -0.10733711823846709\n",
      "Feature: most_rcnt_creat, Weight: -0.10612357659323493\n",
      "Feature: onvent_N, Weight: -0.10087638577452558\n",
      "Feature: ethnicity_0, Weight: -0.0959076876508472\n",
      "Feature: diab_1.0, Weight: -0.08843457853106765\n",
      "Feature: cig_use_Y, Weight: -0.0800589523315842\n",
      "Feature: cereb_vasc_Y, Weight: -0.0768718662163248\n",
      "Feature: education_3.0, Weight: -0.07503160845379751\n",
      "Feature: diab_3.0, Weight: -0.07323850500534024\n",
      "Feature: histry_cig_old_N, Weight: -0.06765253596176972\n",
      "Feature: gender_M, Weight: -0.06603581377414545\n",
      "Feature: ventilator_tcr_0, Weight: -0.06517350858930172\n",
      "Feature: diab_2.0, Weight: -0.059131777507676966\n",
      "Feature: education_6.0, Weight: -0.05886108817702033\n",
      "Feature: education_4.0, Weight: -0.050663938989257466\n",
      "Feature: malig_tcr_Y, Weight: -0.05037521181682263\n",
      "Feature: histry_cig_old_Y, Weight: -0.04584512796307482\n",
      "Feature: init_hgt_cm_calc, Weight: -0.03069248334414423\n",
      "Feature: icu_Y, Weight: -0.029615215221861665\n",
      "Feature: dial_ty_tcr_2.0, Weight: -0.02837893563100012\n",
      "Feature: vas_Y, Weight: -0.026481624681273228\n",
      "Feature: diab_998.0, Weight: -0.02406525508390467\n",
      "Feature: cereb_vasc_U, Weight: -0.023909576388000585\n",
      "Feature: tah_Y, Weight: -0.015136410504745483\n",
      "Feature: dial_ty_tcr_998.0, Weight: -0.011968416513656885\n",
      "Feature: education_5.0, Weight: -0.01173213109679989\n",
      "Feature: abo_A1, Weight: -0.009930095597374271\n",
      "Feature: abo_A1B, Weight: -0.007079728585628631\n",
      "Feature: diab_5.0, Weight: -0.006170621112065879\n",
      "Feature: abo_A, Weight: -0.006039574105810651\n",
      "Feature: dial_ty_tcr_999.0, Weight: -0.005232344148883974\n",
      "Feature: abo_A2B, Weight: -0.004227735673185231\n",
      "Feature: diab_4.0, Weight: -0.0033350023767540703\n",
      "Feature: init_age, Weight: -0.0025243714269651114\n",
      "Feature: thoracic_dgn, Weight: -0.0005530412860218947\n",
      "Feature: func_stat_tcr, Weight: -0.00017495229941596603\n",
      "Feature: abo_A2, Weight: -0.00013204243859473458\n",
      "Feature: init_stat, Weight: 1.2967360519296663e-05\n",
      "Feature: malig_tcr_U, Weight: 0.0026001654136745093\n",
      "Feature: wgt_kg_tcr, Weight: 0.0032855353847817776\n",
      "Feature: init_wgt_kg_calc, Weight: 0.013620715687171965\n",
      "Feature: dial_ty_tcr_3.0, Weight: 0.021249685359303726\n",
      "Feature: education_1.0, Weight: 0.025207588413550433\n",
      "Feature: inotropic_Y, Weight: 0.02803751162177091\n",
      "Feature: hgt_cm_tcr, Weight: 0.028349979913342427\n",
      "Feature: hemo_co_tcr, Weight: 0.03385282061067389\n",
      "Feature: education_2.0, Weight: 0.040215198069485425\n",
      "Feature: iabp_tcr_0, Weight: 0.04081071713065571\n",
      "Feature: work_income_tcr_Y, Weight: 0.07670532105848152\n",
      "Feature: academic_level_tcr_996.0, Weight: 0.10298001974710315\n",
      "Feature: inotropes_tcr_0, Weight: 0.31390643335094637\n",
      "Feature: tot_serum_album, Weight: 0.5381996451349949\n",
      "Feature: abo_O, Weight: 0.6025482954021019\n",
      "Feature: work_income_tcr_U, Weight: 0.6367278709790462\n",
      "Feature: academic_level_tcr_2.0, Weight: 0.6691888808379334\n"
     ]
    }
   ],
   "source": [
    "#Print the weights of the model with the corresponding feature name\n",
    "weights = list(zip(X_new.columns, log.coef_[0]))\n",
    "weights_sorted = sorted(weights, key=lambda x: x[1])\n",
    "for feature, weight in weights_sorted:\n",
    "    print(f\"Feature: {feature}, Weight: {weight}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
