{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"../Data\"\n",
    "base_csv_path = os.path.join(base_dir, 'm0_post_feat_sel_f1.csv')\n",
    "assert os.path.exists(base_csv_path), f\"{base_csv_path} does not exist\"\n",
    "\n",
    "df = pd.read_csv(base_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in wl_time: 0\n",
      "Number of values in wl_time: 65067\n",
      "Median for wl_time: 88.0\n",
      "Percentage of 0 and 1 in wl_time: \n",
      "1    50.148309\n",
      "0    49.851691\n",
      "Name: wl_time, dtype: float64\n",
      "Number of missing values in wl_time: 0\n"
     ]
    }
   ],
   "source": [
    "#Print number of missing values in wl_tme\n",
    "print(f'Number of missing values in wl_time: {df[\"wl_time\"].isnull().sum()}')\n",
    "\n",
    "#Print number of values in wl_time\n",
    "print(f'Number of values in wl_time: {df[\"wl_time\"].count()}')\n",
    "\n",
    "wl_median = df['wl_time'].median()\n",
    "\n",
    "#Print median for wl_time\n",
    "print(f'Median for wl_time: {wl_median}')\n",
    "\n",
    "#Code wl_time to 0 if wl_time is is less than the median else 1\n",
    "df['wl_time'] = df['wl_time'].apply(lambda x: 0 if x < wl_median else 1)\n",
    "\n",
    "#Print percentage of 0 and 1 in wl_time\n",
    "print(f'Percentage of 0 and 1 in wl_time: \\n{df[\"wl_time\"].value_counts(normalize=True) * 100}')\n",
    "\n",
    "#Print number of missing values in wl_time\n",
    "print(f'Number of missing values in wl_time: {df[\"wl_time\"].isnull().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.7645595305198583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example dataset and labels\n",
    "X = df.drop('wl_time', axis=1)\n",
    "y = df['wl_time']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Obtain predicted probabilities on the testing set\n",
    "y_pred = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate AUROC\n",
    "auroc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"AUROC:\", auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X = df.drop(['wl_time'], axis=1)\n",
    "y = df['wl_time']\n",
    "\n",
    "one_hot_cols = [col for col in df.columns if df[col].nunique() == 2]\n",
    "columns_to_scale = [col for col in X.columns if col not in one_hot_cols]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X[columns_to_scale] = scaler.fit_transform(X[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "log = LogisticRegression(max_iter=1000)\n",
    "f1_scores = cross_val_score(log, X, y, cv=5, scoring='f1').mean()\n",
    "print(f\"F1 score pre feature selection: {f1_scores}\")\n",
    "\n",
    "f1_macro_scores = cross_val_score(log, X, y, cv=5, scoring='f1_macro').mean()\n",
    "print(f\"F1 macro score pre feature selection: {f1_macro_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as     np\n",
    "\n",
    "log.fit(X, y)\n",
    "\n",
    "# Get the coefficients (log odds) of the logistic regression model\n",
    "coefficients = log.coef_[0]\n",
    "\n",
    "# Calculate the odds ratio for each feature\n",
    "odds_ratios = np.exp(coefficients)\n",
    "\n",
    "# Display the odds ratio for each feature\n",
    "for feature, odds_ratio in zip(X.columns, odds_ratios):\n",
    "    print(f\"Feature: {feature}, Odds Ratio: {odds_ratio}\")\n",
    "\n",
    "f1_scores = cross_val_score(log, X, y, cv=5, scoring='f1').mean()\n",
    "print(f\"F1 score pre feature selection: {f1_scores}\")\n",
    "\n",
    "f1_macro_scores = cross_val_score(log, X, y, cv=5, scoring='f1_macro').mean()\n",
    "print(f\"F1 macro score pre feature selection: {f1_macro_scores}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(log, X, y, cv=5)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "# Plot the confusion matrix with axes labeled\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "\n",
    "# Set labels for the x and y axes\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual/True\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "#df.corr()\n",
    "#sns.heatmap(df.corr(), annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
