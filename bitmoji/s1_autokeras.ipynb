{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"attributes.csv\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4084 files belonging to 2 classes.\n",
      "['male', 'other']\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.image_dataset import image_dataset_from_directory\n",
    "\n",
    "train_data = image_dataset_from_directory(\n",
    "    \"data\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "print(train_data.class_names)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "`tf.data.Dataset` only supports Python-style iteration in eager mode or within tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[111], line 15\u001B[0m\n\u001B[1;32m      9\u001B[0m output_node \u001B[38;5;241m=\u001B[39m ak\u001B[38;5;241m.\u001B[39mClassificationHead()(output_node)\n\u001B[1;32m     11\u001B[0m auto_model \u001B[38;5;241m=\u001B[39m ak\u001B[38;5;241m.\u001B[39mAutoModel(\n\u001B[1;32m     12\u001B[0m     inputs\u001B[38;5;241m=\u001B[39minput_node, outputs\u001B[38;5;241m=\u001B[39moutput_node, overwrite\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, max_trials\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m\n\u001B[1;32m     13\u001B[0m )\n\u001B[0;32m---> 15\u001B[0m \u001B[43mauto_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/autokeras/auto_model.py:283\u001B[0m, in \u001B[0;36mAutoModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    278\u001B[0m     validation_split \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    280\u001B[0m dataset, validation_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_to_dataset(\n\u001B[1;32m    281\u001B[0m     x\u001B[38;5;241m=\u001B[39mx, y\u001B[38;5;241m=\u001B[39my, validation_data\u001B[38;5;241m=\u001B[39mvalidation_data, batch_size\u001B[38;5;241m=\u001B[39mbatch_size\n\u001B[1;32m    282\u001B[0m )\n\u001B[0;32m--> 283\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_analyze_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_hyper_pipeline(dataset)\n\u001B[1;32m    286\u001B[0m \u001B[38;5;66;03m# Split the data with validation_split.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/autokeras/auto_model.py:369\u001B[0m, in \u001B[0;36mAutoModel._analyze_data\u001B[0;34m(self, dataset)\u001B[0m\n\u001B[1;32m    367\u001B[0m output_analysers \u001B[38;5;241m=\u001B[39m [head\u001B[38;5;241m.\u001B[39mget_analyser() \u001B[38;5;28;01mfor\u001B[39;00m head \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_heads]\n\u001B[1;32m    368\u001B[0m analysers \u001B[38;5;241m=\u001B[39m input_analysers \u001B[38;5;241m+\u001B[39m output_analysers\n\u001B[0;32m--> 369\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x, y \u001B[38;5;129;01min\u001B[39;00m dataset:\n\u001B[1;32m    370\u001B[0m     x \u001B[38;5;241m=\u001B[39m nest\u001B[38;5;241m.\u001B[39mflatten(x)\n\u001B[1;32m    371\u001B[0m     y \u001B[38;5;241m=\u001B[39m nest\u001B[38;5;241m.\u001B[39mflatten(y)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:501\u001B[0m, in \u001B[0;36mDatasetV2.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    499\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m iterator_ops\u001B[38;5;241m.\u001B[39mOwnedIterator(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    500\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 501\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.Dataset` only supports Python-style \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    502\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miteration in eager mode or within tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: `tf.data.Dataset` only supports Python-style iteration in eager mode or within tf.function."
     ]
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "input_node = ak.ImageInput()\n",
    "\n",
    "output_node = ak.Normalization()(input_node)\n",
    "output_node1 = ak.ConvBlock()(output_node)\n",
    "output_node2 = ak.ResNetBlock(version=\"v2\")(output_node)\n",
    "output_node = ak.Merge()([output_node1, output_node2])\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "\n",
    "auto_model = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1000\n",
    ")\n",
    "\n",
    "auto_model.fit(train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
