{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data_120294_2023-03-29_cleaned.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean waiting list time: 192.52839426430694\n",
      "0    0.716807\n",
      "1    0.283193\n",
      "Name: wl_time, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_wl_time = df['wl_time'].mean()\n",
    "print(f\"Mean waiting list time: {mean_wl_time}\")\n",
    "\n",
    "df['wl_time'] = df['wl_time'].apply(lambda x: 0 if x < mean_wl_time else 1)\n",
    "print(df['wl_time'].value_counts(normalize=True))\n",
    "\n",
    "one_hot_cols = [col for col in df.columns if df[col].nunique() == 2]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.4207234479936403\n",
      "F1 macro score: 0.6316114297647631\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[51243,  4245],\n       [14736,  7186]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X = df.drop(['wl_time'], axis=1)\n",
    "y = df['wl_time']\n",
    "\n",
    "columns_to_scale = [col for col in X.columns if col not in one_hot_cols]\n",
    "# scale all columns except the one-hot encoded ones\n",
    "scaler = StandardScaler()\n",
    "X[columns_to_scale] = scaler.fit_transform(X[columns_to_scale])\n",
    "\n",
    "log = LogisticRegression(max_iter=1000)\n",
    "f1_scores = cross_val_score(log, X, y, cv=5, scoring='f1').mean()\n",
    "f1_macro_scores = cross_val_score(log, X, y, cv=5, scoring='f1_macro').mean()\n",
    "\n",
    "print(f\"F1 score: {f1_scores}\")\n",
    "print(f\"F1 macro score: {f1_macro_scores}\")\n",
    "\n",
    "# plot confusion matrix\n",
    "log.fit(X, y)\n",
    "y_pred = log.predict(X)\n",
    "confusion_matrix(y, y_pred)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial F1 score: 0.4207\n",
      "Num of features: 82\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 82 features.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "import numpy as np\n",
    "\n",
    "# Perform k-fold cross-validation and compute the initial F1 score\n",
    "scores = cross_val_score(log, X, y, cv=5, scoring='f1')\n",
    "avg_score = np.mean(scores)\n",
    "print(\"Initial F1 score: {:.4f}\".format(avg_score))\n",
    "\n",
    "selector = RFECV(estimator=log, cv=5, scoring='f1', verbose=1)\n",
    "print(f\"Num of features: {X.shape[1]}\")\n",
    "\n",
    "selector.fit(X, y)\n",
    "\n",
    "print(f\"Optimal number of features: {selector.n_features_}\")\n",
    "print(f\"The mask of the selected features: {selector.support_}\")\n",
    "print(f\"The ranking of the features: {selector.ranking_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_rankings = list(zip(df.columns, selector.ranking_, selector.support_))\n",
    "feature_rankings_sorted = sorted(feature_rankings, key=lambda x: x[1])\n",
    "for feature, ranking, support in feature_rankings_sorted:\n",
    "    print(f\"Feature: {feature}, Ranking: {ranking}, Support: {support}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_selected = df.iloc[:, selector.support_]\n",
    "\n",
    "#Print the shape of the new dataframe\n",
    "print(df_selected.shape)\n",
    "\n",
    "#Add the columns names to the new dataframe\n",
    "df_selected.columns = df.columns[selector.support_]\n",
    "\n",
    "#Print the names of the columns in the new dataframe\n",
    "print(df_selected.columns)\n",
    "\n",
    "#Do a logistic regression on the new dataframe\n",
    "log = LogisticRegression(max_iter=1000)\n",
    "\n",
    "#Fit the model\n",
    "log.fit(df_selected, y)\n",
    "\n",
    "#Print the weights of the model with the corresponding feature name\n",
    "for i in range(len(log.coef_[0])):\n",
    "    print(f\"Feature: {df_selected.columns[i]}, Weight: {log.coef_[0][i]}\")\n",
    "\n",
    "# Perform k-fold cross-validation and compute the initial F1 score\n",
    "scores = cross_val_score(log, X, y, cv=5, scoring='f1')\n",
    "avg_score = np.mean(scores)\n",
    "print(\"F1_score after feature selection: {:.4f}\".format(avg_score))\n",
    "\n",
    "\n",
    "# Create a correlation matrix\n",
    "corr_matrix = df_selected.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
