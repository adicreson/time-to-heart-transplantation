{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 columns with only one unique value\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"space/imputed2.csv\")\n",
    "\n",
    "pre_remov = df.shape[1]\n",
    "df = df.loc[:, df.nunique() != 1]\n",
    "print(f\"Removed {pre_remov - df.shape[1]} columns with only one unique value\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean waiting list time: 192.52839426430694\n",
      "0    0.716807\n",
      "1    0.283193\n",
      "Name: wl_time, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_wl_time = df['wl_time'].mean()\n",
    "print(f\"Mean waiting list time: {mean_wl_time}\")\n",
    "\n",
    "df['wl_time'] = df['wl_time'].apply(lambda x: 0 if x < mean_wl_time else 1)\n",
    "print(df['wl_time'].value_counts(normalize=True))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8952750557996195\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                wl_time   R-squared (uncentered):                   0.359\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.358\n",
      "Method:                 Least Squares   F-statistic:                              323.0\n",
      "Date:                Tue, 18 Apr 2023   Prob (F-statistic):                        0.00\n",
      "Time:                        20:12:56   Log-Likelihood:                         -43793.\n",
      "No. Observations:               77410   AIC:                                  8.785e+04\n",
      "Df Residuals:                   77276   BIC:                                  8.909e+04\n",
      "Df Model:                         134                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0035      0.002     -2.067      0.039      -0.007      -0.000\n",
      "x2             0.0096      0.003      3.489      0.000       0.004       0.015\n",
      "x3            -0.0021      0.002     -1.095      0.273      -0.006       0.002\n",
      "x4            -0.0028      0.002     -1.146      0.252      -0.007       0.002\n",
      "x5             0.0090      0.002      4.493      0.000       0.005       0.013\n",
      "x6             0.0003      0.003      0.075      0.940      -0.007       0.007\n",
      "x7            -0.0167      0.004     -4.618      0.000      -0.024      -0.010\n",
      "x8             0.0049      0.002      2.614      0.009       0.001       0.009\n",
      "x9             0.0112      0.002      7.113      0.000       0.008       0.014\n",
      "x10           -0.0235      0.028     -0.840      0.401      -0.078       0.031\n",
      "x11            0.0236      0.032      0.727      0.467      -0.040       0.087\n",
      "x12         8.731e-06      0.002      0.004      0.997      -0.004       0.004\n",
      "x13           -0.0033      0.002     -1.758      0.079      -0.007       0.000\n",
      "x14            0.0026      0.002      1.348      0.178      -0.001       0.006\n",
      "x15            0.0038      0.002      2.165      0.030       0.000       0.007\n",
      "x16            0.0003      0.002      0.171      0.864      -0.003       0.003\n",
      "x17            0.0022      0.003      0.838      0.402      -0.003       0.008\n",
      "x18           -0.0137      0.002     -6.033      0.000      -0.018      -0.009\n",
      "x19            0.0298      0.002     16.670      0.000       0.026       0.033\n",
      "x20           -0.0116      0.003     -4.415      0.000      -0.017      -0.006\n",
      "x21           -0.0263      0.004     -7.461      0.000      -0.033      -0.019\n",
      "x22            0.0018      0.002      0.975      0.330      -0.002       0.005\n",
      "x23            0.0033      0.002      1.430      0.153      -0.001       0.008\n",
      "x24            0.0070      0.004      1.821      0.069      -0.001       0.015\n",
      "x25           -0.0028      0.002     -1.694      0.090      -0.006       0.000\n",
      "x26            0.0012      0.002      0.772      0.440      -0.002       0.004\n",
      "x27           -0.0038      0.002     -1.744      0.081      -0.008       0.000\n",
      "x28            0.0116      0.002      6.713      0.000       0.008       0.015\n",
      "x29           -0.0016      0.002     -0.972      0.331      -0.005       0.002\n",
      "x30            0.0077      0.002      3.956      0.000       0.004       0.011\n",
      "x31            0.0008      0.004      0.181      0.857      -0.008       0.009\n",
      "x32           -0.0044      0.004     -1.175      0.240      -0.012       0.003\n",
      "x33            0.0026      0.005      0.488      0.625      -0.008       0.013\n",
      "x34            0.0077      0.003      2.385      0.017       0.001       0.014\n",
      "x35            0.0003      0.002      0.147      0.883      -0.004       0.005\n",
      "x36            0.0007      0.002      0.396      0.692      -0.003       0.004\n",
      "x37            0.0019      0.002      1.058      0.290      -0.002       0.005\n",
      "x38           -0.0007      0.002     -0.445      0.656      -0.004       0.003\n",
      "x39            0.0056      0.002      2.989      0.003       0.002       0.009\n",
      "x40            0.0004      0.003      0.138      0.890      -0.005       0.006\n",
      "x41            0.0394      0.002     20.951      0.000       0.036       0.043\n",
      "x42            0.0631      0.002     34.202      0.000       0.059       0.067\n",
      "x43            0.1246      0.003     48.097      0.000       0.120       0.130\n",
      "x44            0.0960      0.002     45.303      0.000       0.092       0.100\n",
      "x45            0.0334      0.002     19.921      0.000       0.030       0.037\n",
      "x46            0.0070      0.002      4.503      0.000       0.004       0.010\n",
      "x47            0.0010      0.002      0.591      0.554      -0.002       0.004\n",
      "x48            0.0088      0.002      5.491      0.000       0.006       0.012\n",
      "x49            0.0009      0.002      0.567      0.570      -0.002       0.004\n",
      "x50            0.0136      0.002      8.664      0.000       0.011       0.017\n",
      "x51            0.0117      0.002      5.472      0.000       0.007       0.016\n",
      "x52            0.0022      0.002      1.399      0.162      -0.001       0.005\n",
      "x53            0.0038      0.002      1.671      0.095      -0.001       0.008\n",
      "x54           -1.8024      0.058    -31.339      0.000      -1.915      -1.690\n",
      "x55           -0.0389      0.003    -13.585      0.000      -0.045      -0.033\n",
      "x56        -8.835e-06      0.002     -0.005      0.996      -0.004       0.004\n",
      "x57           -0.0027      0.002     -1.435      0.151      -0.006       0.001\n",
      "x58           -0.0074      0.004     -1.987      0.047      -0.015      -0.000\n",
      "x59           -0.0658      0.040     -1.654      0.098      -0.144       0.012\n",
      "x60            0.0345      0.032      1.085      0.278      -0.028       0.097\n",
      "x61           -0.0156      0.008     -1.849      0.064      -0.032       0.001\n",
      "x62            0.0191      0.033      0.588      0.557      -0.045       0.083\n",
      "x63           -0.0154      0.026     -0.584      0.559      -0.067       0.036\n",
      "x64            0.0106      0.016      0.661      0.509      -0.021       0.042\n",
      "x65           -0.0012      0.002     -0.641      0.522      -0.005       0.002\n",
      "x66            0.0123      0.002      6.408      0.000       0.009       0.016\n",
      "x67            0.0145      0.004      4.067      0.000       0.008       0.022\n",
      "x68            0.0345      0.002     16.015      0.000       0.030       0.039\n",
      "x69           -0.0016      0.002     -0.870      0.384      -0.005       0.002\n",
      "x70           -0.0096      0.002     -5.005      0.000      -0.013      -0.006\n",
      "x71            0.0003      0.002      0.196      0.844      -0.003       0.004\n",
      "x72            0.0006      0.002      0.312      0.755      -0.003       0.004\n",
      "x73           -0.0022      0.003     -0.706      0.480      -0.008       0.004\n",
      "x74            0.0015      0.002      0.650      0.516      -0.003       0.006\n",
      "x75           -0.0004      0.004     -0.097      0.923      -0.008       0.007\n",
      "x76            0.0031      0.005      0.598      0.550      -0.007       0.013\n",
      "x77           -0.0133      0.003     -4.112      0.000      -0.020      -0.007\n",
      "x78           -0.0048      0.004     -1.139      0.255      -0.013       0.003\n",
      "x79           -0.0062      0.002     -3.472      0.001      -0.010      -0.003\n",
      "x80           -0.0016      0.002     -0.943      0.346      -0.005       0.002\n",
      "x81            0.0010      0.002      0.473      0.636      -0.003       0.005\n",
      "x82            0.0104      0.008      1.252      0.210      -0.006       0.027\n",
      "x83            0.0331      0.030      1.089      0.276      -0.026       0.093\n",
      "x84           -0.0084      0.014     -0.593      0.553      -0.036       0.019\n",
      "x85           -0.0017      0.009     -0.186      0.853      -0.019       0.016\n",
      "x86           -0.0428      0.030     -1.430      0.153      -0.101       0.016\n",
      "x87           -0.0046      0.002     -2.738      0.006      -0.008      -0.001\n",
      "x88           -0.0009      0.002     -0.567      0.570      -0.004       0.002\n",
      "x89            0.0102      0.002      5.728      0.000       0.007       0.014\n",
      "x90            0.0111      0.003      3.550      0.000       0.005       0.017\n",
      "x91            0.0136      0.002      6.615      0.000       0.010       0.018\n",
      "x92           -0.0020      0.002     -0.950      0.342      -0.006       0.002\n",
      "x93            0.0013      0.002      0.818      0.413      -0.002       0.004\n",
      "x94            0.0065      0.003      2.290      0.022       0.001       0.012\n",
      "x95           -0.0059      0.009     -0.627      0.531      -0.024       0.012\n",
      "x96           -0.0018      0.003     -0.649      0.516      -0.007       0.004\n",
      "x97            0.0055      0.010      0.575      0.565      -0.013       0.024\n",
      "x98           -0.0027      0.003     -1.079      0.280      -0.008       0.002\n",
      "x99            0.0028      0.002      1.215      0.224      -0.002       0.007\n",
      "x100          -0.0069      0.039     -0.176      0.861      -0.084       0.070\n",
      "x101          -0.0046      0.033     -0.141      0.888      -0.069       0.059\n",
      "x102          -0.0083      0.037     -0.221      0.825      -0.082       0.065\n",
      "x103           0.0122      0.068      0.181      0.856      -0.120       0.145\n",
      "x104          -0.0111      0.002     -4.619      0.000      -0.016      -0.006\n",
      "x105           0.0309      0.003     10.638      0.000       0.025       0.037\n",
      "x106           0.0098      0.002      4.333      0.000       0.005       0.014\n",
      "x107           0.0006      0.002      0.250      0.803      -0.004       0.005\n",
      "x108          -0.0108      0.002     -6.797      0.000      -0.014      -0.008\n",
      "x109           1.8121      0.058     31.324      0.000       1.699       1.926\n",
      "x110           0.0046      0.005      0.993      0.320      -0.004       0.014\n",
      "x111           0.0053      0.002      2.561      0.010       0.001       0.009\n",
      "x112       -8.516e-05      0.002     -0.045      0.964      -0.004       0.004\n",
      "x113          -0.0030      0.003     -0.874      0.382      -0.010       0.004\n",
      "x114           0.0155      0.026      0.591      0.555      -0.036       0.067\n",
      "x115           0.0408      0.024      1.723      0.085      -0.006       0.087\n",
      "x116           0.0067      0.015      0.448      0.654      -0.023       0.036\n",
      "x117          -0.0109      0.002     -5.151      0.000      -0.015      -0.007\n",
      "x118           0.0155      0.006      2.490      0.013       0.003       0.028\n",
      "x119          -0.0040      0.002     -1.937      0.053      -0.008    4.86e-05\n",
      "x120          -0.0008      0.002     -0.356      0.722      -0.005       0.004\n",
      "x121          -0.0003      0.003     -0.087      0.930      -0.007       0.006\n",
      "x122          -0.0008      0.002     -0.484      0.628      -0.004       0.003\n",
      "x123           0.0055      0.002      2.957      0.003       0.002       0.009\n",
      "x124           0.0049      0.005      1.001      0.317      -0.005       0.015\n",
      "x125           0.0025      0.003      0.879      0.379      -0.003       0.008\n",
      "x126          -0.0020      0.005     -0.410      0.682      -0.011       0.008\n",
      "x127           0.0048      0.002      2.638      0.008       0.001       0.008\n",
      "x128           0.0026      0.002      1.576      0.115      -0.001       0.006\n",
      "x129          -0.0028      0.006     -0.448      0.654      -0.015       0.009\n",
      "x130          -0.0038      0.002     -1.723      0.085      -0.008       0.001\n",
      "x131           0.0102      0.003      3.275      0.001       0.004       0.016\n",
      "x132           0.0010      0.003      0.364      0.716      -0.004       0.006\n",
      "x133           0.0092      0.007      1.407      0.160      -0.004       0.022\n",
      "x134           0.0038      0.002      1.669      0.095      -0.001       0.008\n",
      "==============================================================================\n",
      "Omnibus:                     5939.179   Durbin-Watson:                   1.114\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            16846.391\n",
      "Skew:                           0.422   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.124   Cond. No.                         223.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "   num_prev_tx  thoracic_dgn  tah  vas  onvent  icu  inotropic  gender  abo  \\\n",
      "0          0.0        1000.0  0.0  0.0     0.0  0.0        1.0     1.0  0.0   \n",
      "1          0.0        1007.0  0.1  0.0     0.0  0.6        0.1     1.0  7.0   \n",
      "2          0.0        1203.0  0.0  0.0     0.0  1.0        1.0     1.0  0.0   \n",
      "3          0.0        1000.0  0.0  0.0     0.0  1.0        1.0     1.0  7.0   \n",
      "4          0.0        1999.0  0.0  0.0     0.0  1.0        1.0     1.0  7.0   \n",
      "\n",
      "   wgt_kg_tcr  ...  simulect_maint  steroids_ind  steroids_maint  prograf_ind  \\\n",
      "0      76.200  ...             0.0           1.0             1.0          0.0   \n",
      "1      92.533  ...             0.0           1.0             1.0          0.0   \n",
      "2      25.500  ...             0.0           0.0             1.0          0.0   \n",
      "3      70.760  ...             0.0           1.0             1.0          1.0   \n",
      "4      60.000  ...             0.0           1.0             1.0          1.0   \n",
      "\n",
      "   prograf_maint  imuran_ind  imuran_maint  cellcept_ind  cellcept_maint  \\\n",
      "0            1.0         0.0           1.0           0.0             1.0   \n",
      "1            1.0         0.8           0.4           0.0             1.0   \n",
      "2            1.0         0.0           1.0           0.0             1.0   \n",
      "3            1.0         1.0           1.0           1.0             1.0   \n",
      "4            0.9         1.0           1.0           1.0             0.5   \n",
      "\n",
      "   wl_time  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n",
      "\n",
      "[5 rows x 135 columns]\n",
      "Number of variables: 135\n",
      "Removing dial_after_list with p-value 0.991736166937915\n",
      "Number of variables: 134\n",
      "Removing days_stata5 with p-value 0.9994506875410206\n",
      "Number of variables: 133\n",
      "Removing ptime with p-value 0.999712000007871\n",
      "Number of variables: 132\n",
      "Removing num_prev_tx with p-value 0.9986019024580539\n",
      "Number of variables: 131\n",
      "Removing pramr_cl2 with p-value 0.9544260101669606\n",
      "Number of variables: 130\n",
      "Removing cyclosporin_maint with p-value 0.9946101030293001\n",
      "Number of variables: 129\n",
      "Removing gtime with p-value 0.9902228342598783\n",
      "Number of variables: 128\n",
      "Removing amis with p-value 0.9903712298244589\n",
      "Number of variables: 127\n",
      "Removing tcr_dgn with p-value 0.8972196049359661\n",
      "Number of variables: 126\n",
      "Removing days_stat1a with p-value 0.9997228655876191\n",
      "Number of variables: 125\n",
      "Removing ecmo_tcr with p-value 0.998762386468139\n",
      "Number of variables: 124\n",
      "Removing days_stata6 with p-value 0.99777686482423\n",
      "Number of variables: 123\n",
      "Removing cyclosporin_ind with p-value 0.9939129341284243\n",
      "Number of variables: 122\n",
      "Removing histry_cig_old with p-value 0.9990093435623385\n",
      "Number of variables: 121\n",
      "Removing hemo_pa_mn_tcr with p-value 0.9935977283125712\n",
      "Number of variables: 120\n",
      "Removing inotrop_vaso_dia_trr with p-value 0.9983709196107673\n",
      "Number of variables: 119\n",
      "Removing inhaled_no with p-value 0.9586810078475896\n",
      "Number of variables: 118\n",
      "Removing imuran_ind with p-value 0.9917911762885576\n",
      "Number of variables: 117\n",
      "Removing hemo_sys_trr with p-value 0.996956720070394\n",
      "Number of variables: 116\n",
      "Removing vad_device_ty_tcr with p-value 0.998858360902197\n",
      "Number of variables: 115\n",
      "Removing hemo_pa_mn_trr with p-value 0.9611619986790261\n",
      "Number of variables: 114\n",
      "Removing hemo_pa_dia_trr with p-value 0.9836163069194315\n",
      "Number of variables: 113\n",
      "Removing ischtime with p-value 0.9998692835833228\n",
      "Number of variables: 112\n",
      "Removing gender with p-value 0.9981968697157086\n",
      "Number of variables: 111\n",
      "Removing simulect_maint with p-value 0.9902804861773431\n",
      "Number of variables: 110\n",
      "Removing neoral_maint with p-value 0.9957515548971039\n",
      "Number of variables: 109\n",
      "Removing cellcept_ind with p-value 0.9999855599662385\n",
      "Number of variables: 108\n",
      "Removing days_stata1 with p-value 0.9999407820491464\n",
      "Number of variables: 107\n",
      "Removing age_group with p-value 0.9999804858029169\n",
      "Number of variables: 106\n",
      "Removing prograf_maint with p-value 0.9998925739238234\n",
      "Number of variables: 105\n",
      "Removing inotropes_tcr with p-value 0.9999810330190979\n",
      "Number of variables: 104\n",
      "Removing rem_cd with p-value 0.9999455676845374\n",
      "Number of variables: 103\n",
      "Removing dial_ty_tcr with p-value 0.988116409075425\n",
      "Number of variables: 102\n",
      "Removing abo_mat with p-value 0.9907662763834388\n",
      "Number of variables: 101\n",
      "Removing end_wgt_kg_calc with p-value 0.7312089409160676\n",
      "Number of variables: 100\n",
      "Removing most_rcnt_creat with p-value 0.9992971719126034\n",
      "Number of variables: 99\n",
      "Removing hlamis with p-value 0.9684855202564026\n",
      "Number of variables: 98\n",
      "Removing distance with p-value 0.9934479840219476\n",
      "Number of variables: 97\n",
      "Removing init_bmi_calc with p-value 0.9960777748263747\n",
      "Number of variables: 96\n",
      "Removing days_stat1b with p-value 0.9914492447248819\n",
      "Number of variables: 95\n",
      "Removing transfusions with p-value 0.9730782029218011\n",
      "Number of variables: 94\n",
      "Removing init_stat with p-value 0.9878819591675355\n",
      "Number of variables: 93\n",
      "Removing days_stata4 with p-value 0.8592499843303907\n",
      "Number of variables: 92\n",
      "Removing diab with p-value 0.9983729846814469\n",
      "Number of variables: 91\n",
      "Removing hemo_pcw_tcr with p-value 0.937502426147133\n",
      "Number of variables: 90\n",
      "Removing malig_tcr with p-value 0.9998619347812215\n",
      "Number of variables: 89\n",
      "Removing prapk with p-value 0.9961688021272356\n",
      "Number of variables: 88\n",
      "Removing vad_device_ty_trr with p-value 0.9999558877454549\n",
      "Number of variables: 87\n",
      "Removing inotropes_trr with p-value 0.99906170898571\n",
      "Number of variables: 86\n",
      "Removing pge_trr with p-value 0.9996776009697772\n",
      "Number of variables: 85\n",
      "Removing days_stat1 with p-value 0.9969482096804514\n",
      "Number of variables: 84\n",
      "Removing iabp_tcr with p-value 0.9999712531281937\n",
      "Number of variables: 83\n",
      "Removing init_hgt_cm_calc with p-value 0.9806764954075232\n",
      "Number of variables: 82\n",
      "Removing bmi_tcr with p-value 0.9886487803820995\n",
      "Number of variables: 81\n",
      "Removing drmis with p-value 0.9777132118455182\n",
      "Number of variables: 80\n",
      "Removing neoral_ind with p-value 0.943055398255233\n",
      "Number of variables: 79\n",
      "Removing px_stat with p-value 0.9724208837430068\n",
      "Number of variables: 78\n",
      "Removing end_stat with p-value 0.8832979739249018\n",
      "Number of variables: 77\n",
      "Removing hemo_pa_dia_tcr with p-value 0.9959430848710872\n",
      "Number of variables: 76\n",
      "Removing tah with p-value 0.9751413961332155\n",
      "Number of variables: 75\n",
      "Removing pramr with p-value 0.9925723666649454\n",
      "Number of variables: 74\n",
      "Removing hemo_sys_tcr with p-value 0.9954600463206706\n",
      "Number of variables: 73\n",
      "Removing func_stat_trf with p-value 0.9902654894843944\n",
      "Number of variables: 72\n",
      "Removing inotrop_vaso_co_trr with p-value 0.9977262043294118\n",
      "Number of variables: 71\n",
      "Removing lastfuno with p-value 0.9986802829003463\n",
      "Number of variables: 70\n",
      "Removing hgt_cm_tcr with p-value 0.9997529934933818\n",
      "Number of variables: 69\n",
      "Removing hemo_pcw_trr with p-value 0.7026309913265676\n",
      "Number of variables: 68\n",
      "Removing dial_prior_tx with p-value 0.999741798004977\n",
      "Number of variables: 67\n",
      "Removing inotropic with p-value 0.984600907434811\n",
      "Number of variables: 66\n",
      "Removing days_stata3 with p-value 0.9992978563797961\n",
      "Number of variables: 65\n",
      "Removing prior_card_surg_type_trr with p-value 0.9974606662859369\n",
      "Number of variables: 64\n",
      "Removing cereb_vasc with p-value 0.999957742860963\n",
      "Number of variables: 63\n",
      "Removing ventilator_tcr with p-value 0.9663148990737639\n",
      "Number of variables: 62\n",
      "Removing cod with p-value 0.9720644524197033\n",
      "Number of variables: 61\n",
      "Removing age with p-value 0.993631456364398\n",
      "Number of variables: 60\n",
      "Removing vad_tah_tcr with p-value 0.9998878117448216\n",
      "Number of variables: 59\n",
      "Removing hemo_co_trr with p-value 0.9461707503801695\n",
      "Number of variables: 58\n",
      "Removing imuran_maint with p-value 0.3555061795178798\n",
      "Number of variables: 57\n",
      "Removing pramr_cl1 with p-value 0.9997284559078785\n",
      "Number of variables: 56\n",
      "Removing hemo_co_tcr with p-value 0.8608167107371758\n",
      "Number of variables: 55\n",
      "Removing bmis with p-value 0.9858779058888649\n",
      "Number of variables: 54\n",
      "Removing simulect_ind with p-value 0.9077748740692486\n",
      "Number of variables: 53\n",
      "Removing thymoglobulin_maint with p-value 0.9953960152959362\n",
      "Number of variables: 52\n",
      "Removing thoracic_dgn with p-value 0.9954844083221752\n",
      "Number of variables: 51\n",
      "Removing ecmo_trr with p-value 0.9950680098253188\n",
      "Number of variables: 50\n",
      "Removing tx_year with p-value 0.9995321497936661\n",
      "Number of variables: 49\n",
      "Removing tot_serum_album with p-value 0.9838406171470508\n",
      "Number of variables: 48\n",
      "Removing wgt_kg_calc with p-value 0.7666247846252441\n",
      "Number of variables: 47\n",
      "Removing ethnicity with p-value 0.9061740767322228\n",
      "Number of variables: 46\n",
      "Removing func_stat_trr with p-value 0.9830289082446455\n",
      "Number of variables: 45\n",
      "Removing wgt_kg_tcr with p-value 0.9839996565031428\n",
      "Number of variables: 44\n",
      "Removing init_wgt_kg_calc with p-value 0.9550505738785948\n",
      "Number of variables: 43\n",
      "Removing inotrop_vaso_sys_trr with p-value 0.9899135308259097\n",
      "Number of variables: 42\n",
      "Removing cmv_status with p-value 0.9911108107769779\n",
      "Number of variables: 41\n",
      "Removing cig_use with p-value 0.9999992366273052\n",
      "Number of variables: 40\n",
      "Removing end_hgt_cm_calc with p-value 0.9998840512900331\n",
      "Number of variables: 39\n",
      "Removing inotrop_vaso_pcw_trr with p-value 0.9999355909053165\n",
      "Number of variables: 38\n",
      "Removing tbili with p-value 0.9996708772166784\n",
      "Number of variables: 37\n",
      "Removing prior_card_surg_tcr with p-value 0.9997858052580462\n",
      "Number of variables: 36\n",
      "Removing work_income_trr with p-value 0.9999703907022571\n",
      "Number of variables: 35\n",
      "Removing grf_stat with p-value 0.9998598508410363\n",
      "Number of variables: 34\n",
      "Removing cellcept_maint with p-value 0.9999860589225773\n",
      "Number of variables: 33\n",
      "Removing steroids_maint with p-value 0.9983565589074863\n",
      "Number of variables: 32\n",
      "Removing days_stata2 with p-value 0.988209236327513\n",
      "Number of variables: 31\n",
      "Removing sud_death with p-value 0.9980871936416449\n",
      "Number of variables: 30\n",
      "Removing init_age with p-value 0.9547203059198064\n",
      "Number of variables: 29\n",
      "Removing prograf_ind with p-value 0.9947116286036224\n",
      "Number of variables: 28\n",
      "Removing steroids_ind with p-value 0.9918603428142441\n",
      "Number of variables: 27\n",
      "Removing inotrop_vaso_mn_trr with p-value 0.365347261218783\n",
      "Number of variables: 26\n",
      "Removing med_cond_trr with p-value 0.884075373696537\n",
      "Number of variables: 25\n",
      "Removing work_income_tcr with p-value 0.9997820264984427\n",
      "Number of variables: 24\n",
      "Removing impl_defibril with p-value 0.999972944924421\n",
      "Number of variables: 23\n",
      "Removing steroid with p-value 0.9949152534953678\n",
      "Number of variables: 22\n",
      "Removing life_sup_tcr with p-value 0.9990436084585063\n",
      "Number of variables: 21\n",
      "Removing ethcat with p-value 0.9997349357679045\n",
      "Number of variables: 20\n",
      "Removing thymoglobulin_ind with p-value 0.9993351445206646\n",
      "Number of variables: 19\n",
      "Removing creat_trr with p-value 0.9997119019941922\n",
      "Number of variables: 18\n",
      "Removing iabp_trr with p-value 0.9999004929528414\n",
      "Number of variables: 17\n",
      "Removing vas with p-value 0.9986437992436286\n",
      "Number of variables: 16\n",
      "Removing gstatus with p-value 0.999929082839853\n",
      "Number of variables: 15\n",
      "Removing tcr_dur_abstain with p-value 0.9992759860341717\n",
      "Number of variables: 14\n",
      "Removing vad_brand1_tcr with p-value 0.99998531703593\n",
      "Number of variables: 13\n",
      "Removing education with p-value 0.9998023609778443\n",
      "Number of variables: 12\n",
      "Removing end_bmi_calc with p-value 0.9986865788427941\n",
      "Number of variables: 11\n",
      "Removing infect_iv_drug_trr with p-value 0.998645627025424\n",
      "Number of variables: 10\n",
      "Removing sternotomy_tcr with p-value 0.9947161047292481\n",
      "Number of variables: 9\n",
      "Removing days_stat2 with p-value 0.9988434367241386\n",
      "Number of variables: 8\n",
      "Removing bmi_calc with p-value 0.9996795427072975\n",
      "Number of variables: 7\n",
      "Removing abo with p-value 0.9968233162302381\n",
      "Number of variables: 6\n",
      "Removing icu with p-value 0.9926593355163219\n",
      "Number of variables: 5\n",
      "F1 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "CV = 5\n",
    "\n",
    "X = df.drop(['wl_time'], axis=1)\n",
    "#X = X.iloc[:, :20]# Scale down X to only 10 features\n",
    "y = df['wl_time']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "log = LogisticRegression(max_iter=1000)\n",
    "scores = cross_val_score(log, X, y, cv=CV, scoring='f1').mean()\n",
    "print(\"F1 score:\", scores)\n",
    "\n",
    "\n",
    "logit_model = sm.OLS(y, X)\n",
    "result = logit_model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "X_opt = df\n",
    "\n",
    "print(X_opt.head())\n",
    "SIGNIFICANCE_LEVEL = 0.05\n",
    "\n",
    "while True:\n",
    "    print(f\"Number of variables: {len(X_opt.columns)}\")\n",
    "    model = sm.OLS(y, X_opt).fit()\n",
    "    p_values = model.pvalues\n",
    "    max_p_value = p_values.max()\n",
    "\n",
    "    if max_p_value <= SIGNIFICANCE_LEVEL:\n",
    "        break\n",
    "\n",
    "    print(f\"Removing {p_values.idxmax()} with p-value {max_p_value}\")\n",
    "    X_opt = X_opt.drop([p_values.idxmax()], axis=1)\n",
    "\n",
    "X_opt.head()\n",
    "\n",
    "#result = logit_model.fit()\n",
    "#print(result.summary())\n",
    "\n",
    "log = LogisticRegression(max_iter=1000)\n",
    "scores = cross_val_score(log, X_opt, y, cv=CV, scoring='f1').mean()\n",
    "print(\"F1 score:\", scores)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "data": {
      "text/plain": "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3474c942ae274f839fa99084dada3795"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec74c2d9d5be439fbf8d118a3f59e77b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/20 0/20 F1 = 0.36052876718467175\n",
      "0/20 1/20 F1 = 0.3495625775774318\n",
      "0/20 2/20 F1 = 0.3559559075333286\n",
      "0/20 3/20 F1 = 0.35983261752095164\n",
      "0/20 4/20 F1 = 0.36053856744595564\n",
      "0/20 5/20 F1 = 0.35337475872728275\n",
      "0/20 6/20 F1 = 0.3614389043544609\n",
      "0/20 7/20 F1 = 0.35909242007446973\n",
      "0/20 8/20 F1 = 0.3346404537997382\n",
      "0/20 9/20 F1 = 0.3226628649354059\n",
      "0/20 10/20 F1 = 0.36040109513966023\n",
      "0/20 11/20 F1 = 0.36080327370300314\n",
      "0/20 12/20 F1 = 0.3603882382241522\n",
      "0/20 13/20 F1 = 0.35973271948027435\n",
      "0/20 14/20 F1 = 0.35550269583625266\n",
      "0/20 15/20 F1 = 0.3605916608849584\n",
      "0/20 16/20 F1 = 0.2996030110122348\n",
      "0/20 17/20 F1 = 0.34695054716962487\n",
      "0/20 18/20 F1 = 0.29257285668340194\n",
      "0/20 19/20 F1 = 0.35856589929878274\n",
      "0/20 Best feature: 18 F1 = 0.06822191699532798 Worst feature: 6 F1 = -0.0006441306757309917\n",
      "1/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae78f26191c343d0bf483be9e667e7a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/20 0/19 F1 = 0.36054015011394436\n",
      "1/20 1/19 F1 = 0.3495025731996222\n",
      "1/20 2/19 F1 = 0.35552207541887204\n",
      "1/20 3/19 F1 = 0.3606771127159417\n",
      "1/20 4/19 F1 = 0.362213502081814\n",
      "1/20 5/19 F1 = 0.31483338632459096\n",
      "1/20 7/19 F1 = 0.35954052312970547\n",
      "1/20 8/19 F1 = 0.33339584411589346\n",
      "1/20 9/19 F1 = 0.32248912815099995\n",
      "1/20 10/19 F1 = 0.36166132951343966\n",
      "1/20 11/19 F1 = 0.3615698823470906\n",
      "1/20 12/19 F1 = 0.36212192774806534\n",
      "1/20 13/19 F1 = 0.36011646094523597\n",
      "1/20 14/19 F1 = 0.3565577318249794\n",
      "1/20 15/19 F1 = 0.3615402022698575\n",
      "1/20 16/19 F1 = 0.2999914729878513\n",
      "1/20 17/19 F1 = 0.34822190006637976\n",
      "1/20 18/19 F1 = 0.2920665894033698\n",
      "1/20 19/19 F1 = 0.3574133490886595\n",
      "1/20 Best feature: 18 F1 = 0.0687281842753601 Worst feature: 4 F1 = -0.0014187284030841019\n",
      "2/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae6f14ea36934ac2b5738cb916354bd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/20 0/18 F1 = 0.3612969563571464\n",
      "2/20 1/18 F1 = 0.3495962825239095\n",
      "2/20 2/18 F1 = 0.3554906187706134\n",
      "2/20 3/18 F1 = 0.3606513066727163\n",
      "2/20 5/18 F1 = 0.3132937170773623\n",
      "2/20 7/18 F1 = 0.35973987219993264\n",
      "2/20 8/18 F1 = 0.3333780435942901\n",
      "2/20 9/18 F1 = 0.32266491274483344\n",
      "2/20 10/18 F1 = 0.36181654809506053\n",
      "2/20 11/18 F1 = 0.36224546975444627\n",
      "2/20 12/18 F1 = 0.3618681133408029\n",
      "2/20 13/18 F1 = 0.36080450797048425\n",
      "2/20 14/18 F1 = 0.35672474747798055\n",
      "2/20 15/18 F1 = 0.36215070204453725\n",
      "2/20 16/18 F1 = 0.3000449115568293\n",
      "2/20 17/18 F1 = 0.34783454392798135\n",
      "2/20 18/18 F1 = 0.2916394473214655\n",
      "2/20 19/18 F1 = 0.3574721238519918\n",
      "2/20 Best feature: 18 F1 = 0.0691553263572644 Worst feature: 11 F1 = -0.0014506960757163512\n",
      "3/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "952bb94aa4554c28906411a6512b9d2e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/20 0/17 F1 = 0.361581349295646\n",
      "3/20 1/17 F1 = 0.34990416173007377\n",
      "3/20 2/17 F1 = 0.3553796452039671\n",
      "3/20 3/17 F1 = 0.3602904724835031\n",
      "3/20 5/17 F1 = 0.3129655068736974\n",
      "3/20 7/17 F1 = 0.35969674697406084\n",
      "3/20 8/17 F1 = 0.33337509790140063\n",
      "3/20 9/17 F1 = 0.322751989737674\n",
      "3/20 10/17 F1 = 0.3619169356283731\n",
      "3/20 12/17 F1 = 0.3617735451549744\n",
      "3/20 13/17 F1 = 0.3610094969847398\n",
      "3/20 14/17 F1 = 0.35663134117136697\n",
      "3/20 15/17 F1 = 0.36224730538747874\n",
      "3/20 16/17 F1 = 0.30001951019419526\n",
      "3/20 17/17 F1 = 0.34802549366745567\n",
      "3/20 18/17 F1 = 0.2914967050567264\n",
      "3/20 19/17 F1 = 0.35717343009098645\n",
      "3/20 Best feature: 18 F1 = 0.0692980686220035 Worst feature: 15 F1 = -0.0014525317087488165\n",
      "4/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9be1486d176a4f80b8a2a04e983a282e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/20 0/16 F1 = 0.3615727615118547\n",
      "4/20 1/16 F1 = 0.3498732273088875\n",
      "4/20 2/16 F1 = 0.35517375426947567\n",
      "4/20 3/16 F1 = 0.36040702981220596\n",
      "4/20 5/16 F1 = 0.31308646250661065\n",
      "4/20 7/16 F1 = 0.3596684501770619\n",
      "4/20 8/16 F1 = 0.3332758192242701\n",
      "4/20 9/16 F1 = 0.32275471647406756\n",
      "4/20 10/16 F1 = 0.36188934868093353\n",
      "4/20 12/16 F1 = 0.3617071055311857\n",
      "4/20 13/16 F1 = 0.36098528661483276\n",
      "4/20 14/16 F1 = 0.35685917933387523\n",
      "4/20 16/16 F1 = 0.3000643944629895\n",
      "4/20 17/16 F1 = 0.3480995155175628\n",
      "4/20 18/16 F1 = 0.2914047498958202\n",
      "4/20 19/16 F1 = 0.3570993568736656\n",
      "4/20 Best feature: 18 F1 = 0.0693900237829097 Worst feature: 10 F1 = -0.0010945750022036127\n",
      "5/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb42cdddcf92437f9f1dfef6b78d5e14"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/20 0/15 F1 = 0.3614501850216113\n",
      "5/20 1/15 F1 = 0.34909009299402105\n",
      "5/20 2/15 F1 = 0.3555428707859639\n",
      "5/20 3/15 F1 = 0.36119802682255847\n",
      "5/20 5/15 F1 = 0.31278458270806825\n",
      "5/20 7/15 F1 = 0.3585804699463964\n",
      "5/20 8/15 F1 = 0.33334908891571463\n",
      "5/20 9/15 F1 = 0.2784978109604455\n",
      "5/20 12/15 F1 = 0.3617922869030261\n",
      "5/20 13/15 F1 = 0.3607703112301265\n",
      "5/20 14/15 F1 = 0.3565036617440292\n",
      "5/20 16/15 F1 = 0.3002175384053377\n",
      "5/20 17/15 F1 = 0.34774459923197104\n",
      "5/20 18/15 F1 = 0.2922479039813861\n",
      "5/20 19/15 F1 = 0.35757612447784065\n",
      "5/20 Best feature: 9 F1 = 0.0822969627182844 Worst feature: 12 F1 = -0.0009975132242961982\n",
      "6/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a8f212d5ae340e8b585d0313f456cde"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/20 0/14 F1 = 0.3615205797075361\n",
      "6/20 1/14 F1 = 0.34581419627216975\n",
      "6/20 2/14 F1 = 0.35555471545107636\n",
      "6/20 3/14 F1 = 0.3606218742934073\n",
      "6/20 5/14 F1 = 0.3144496477873468\n",
      "6/20 7/14 F1 = 0.36007159826918667\n",
      "6/20 8/14 F1 = 0.33415517665267946\n",
      "6/20 9/14 F1 = 0.28243751448563137\n",
      "6/20 13/14 F1 = 0.3604461096500111\n",
      "6/20 14/14 F1 = 0.35706456781644585\n",
      "6/20 16/14 F1 = 0.30130291896248207\n",
      "6/20 17/14 F1 = 0.34662453393645104\n",
      "6/20 18/14 F1 = 0.29404592302131205\n",
      "6/20 19/14 F1 = 0.3585793691398013\n",
      "6/20 Best feature: 9 F1 = 0.07835725919309855 Worst feature: 0 F1 = -0.0007258060288061752\n",
      "7/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a0942236edb48d4bb59f0d2967bb5b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/20 1/13 F1 = 0.34540166857241955\n",
      "7/20 2/13 F1 = 0.3554980572717603\n",
      "7/20 3/13 F1 = 0.36024399657119704\n",
      "7/20 5/13 F1 = 0.31419103695268974\n",
      "7/20 7/13 F1 = 0.3599216766703314\n",
      "7/20 8/13 F1 = 0.33439070898809503\n",
      "7/20 9/13 F1 = 0.2828849311173293\n",
      "7/20 13/13 F1 = 0.3605285721663563\n",
      "7/20 14/13 F1 = 0.35629185188309526\n",
      "7/20 16/13 F1 = 0.30149758052137\n",
      "7/20 17/13 F1 = 0.3468005262534735\n",
      "7/20 18/13 F1 = 0.294059437653\n",
      "7/20 19/13 F1 = 0.3583486330610771\n",
      "7/20 Best feature: 9 F1 = 0.0779098425614006 Worst feature: 13 F1 = 0.00026620151237360945\n",
      "8/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8abee2bc2b1a4724aba82577ea762799"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/20 1/12 F1 = 0.34477380624160425\n",
      "8/20 2/12 F1 = 0.3545482813757973\n",
      "8/20 3/12 F1 = 0.3593593920889785\n",
      "8/20 5/12 F1 = 0.312552102157915\n",
      "8/20 7/12 F1 = 0.35793737558778793\n",
      "8/20 8/12 F1 = 0.33286615902537425\n",
      "8/20 9/12 F1 = 0.27785933944358526\n",
      "8/20 14/12 F1 = 0.35475553961846334\n",
      "8/20 16/12 F1 = 0.2999870153430546\n",
      "8/20 17/12 F1 = 0.34529212785996033\n",
      "8/20 18/12 F1 = 0.29353136190583873\n",
      "8/20 19/12 F1 = 0.35747013814736983\n",
      "8/20 Best feature: 9 F1 = 0.08293543423514466 Worst feature: 3 F1 = 0.0014353815897514277\n",
      "9/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b755f469d205442599ce0b343636bb66"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/20 1/11 F1 = 0.3433068137504962\n",
      "9/20 2/11 F1 = 0.3519424924338269\n",
      "9/20 5/11 F1 = 0.31180485486505105\n",
      "9/20 7/11 F1 = 0.3569286324057207\n",
      "9/20 8/11 F1 = 0.33143221093735653\n",
      "9/20 9/11 F1 = 0.2759583243578848\n",
      "9/20 14/11 F1 = 0.35476955015159967\n",
      "9/20 16/11 F1 = 0.2994366400381934\n",
      "9/20 17/11 F1 = 0.34425145533436585\n",
      "9/20 18/11 F1 = 0.2914944531929139\n",
      "9/20 19/11 F1 = 0.35628451125186567\n",
      "9/20 Best feature: 9 F1 = 0.08483644932084511 Worst feature: 7 F1 = 0.003866141273009216\n",
      "10/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b873e0aa44b4db884fbe55d0eb1bcdf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/20 1/10 F1 = 0.3428499701146565\n",
      "10/20 2/10 F1 = 0.35117482248085274\n",
      "10/20 5/10 F1 = 0.3091998776096826\n",
      "10/20 8/10 F1 = 0.32982665773405123\n",
      "10/20 9/10 F1 = 0.2473549081037203\n",
      "10/20 14/10 F1 = 0.35208626317765246\n",
      "10/20 16/10 F1 = 0.29733227147238844\n",
      "10/20 17/10 F1 = 0.3422734601264089\n",
      "10/20 18/10 F1 = 0.2880552710812191\n",
      "10/20 19/10 F1 = 0.35430104616420804\n",
      "10/20 Best feature: 9 F1 = 0.11343986557500962 Worst feature: 19 F1 = 0.006493727514521874\n",
      "11/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcf24c70162049b299ffbf17c546bbff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/20 1/9 F1 = 0.3379383203527418\n",
      "11/20 2/9 F1 = 0.34578701426878544\n",
      "11/20 5/9 F1 = 0.30859260477527173\n",
      "11/20 8/9 F1 = 0.3269225051031351\n",
      "11/20 9/9 F1 = 0.24542822805189565\n",
      "11/20 14/9 F1 = 0.34853272900279986\n",
      "11/20 16/9 F1 = 0.29360240268578536\n",
      "11/20 17/9 F1 = 0.3421288301317296\n",
      "11/20 18/9 F1 = 0.28940897384761\n",
      "11/20 Best feature: 9 F1 = 0.11536654562683427 Worst feature: 14 F1 = 0.012262044675930062\n",
      "12/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "758448e4ceb04237819ed95499b665e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20 1/8 F1 = 0.3331844831805749\n",
      "12/20 2/8 F1 = 0.34137336467175583\n",
      "12/20 5/8 F1 = 0.29648975286660795\n",
      "12/20 8/8 F1 = 0.32011576531193214\n",
      "12/20 9/8 F1 = 0.2424616812866825\n",
      "12/20 16/8 F1 = 0.28194022290648924\n",
      "12/20 17/8 F1 = 0.33605521027346114\n",
      "12/20 18/8 F1 = 0.28216842057653013\n",
      "12/20 Best feature: 9 F1 = 0.11833309239204742 Worst feature: 2 F1 = 0.01942140900697409\n",
      "13/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17ad2c4481744c9680169b5de2250b68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/20 1/7 F1 = 0.3222900020807448\n",
      "13/20 5/7 F1 = 0.2937279688267662\n",
      "13/20 8/7 F1 = 0.31382315866519\n",
      "13/20 9/7 F1 = 0.24324922272273136\n",
      "13/20 16/7 F1 = 0.2739680308801988\n",
      "13/20 17/7 F1 = 0.3301977663363591\n",
      "13/20 18/7 F1 = 0.27957002264241104\n",
      "13/20 Best feature: 9 F1 = 0.11754555095599856 Worst feature: 17 F1 = 0.030597007342370808\n",
      "14/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e29ee465a020478689e2ab3b62793555"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/20 1/6 F1 = 0.3147628075448939\n",
      "14/20 5/6 F1 = 0.274589306214473\n",
      "14/20 8/6 F1 = 0.3015300444634485\n",
      "14/20 9/6 F1 = 0.23524951247784295\n",
      "14/20 16/6 F1 = 0.265499982131184\n",
      "14/20 18/6 F1 = 0.26891979498145574\n",
      "14/20 Best feature: 9 F1 = 0.12554526120088697 Worst feature: 1 F1 = 0.04603196613383603\n",
      "15/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "488718303a5e4c2ab96fed45e2b043f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/20 5/5 F1 = 0.25839030244214684\n",
      "15/20 8/5 F1 = 0.2887394657553083\n",
      "15/20 9/5 F1 = 0.1967965448187055\n",
      "15/20 16/5 F1 = 0.26042833444801616\n",
      "15/20 18/5 F1 = 0.25347475264024877\n",
      "15/20 Best feature: 9 F1 = 0.1639982288600244 Worst feature: 8 F1 = 0.07205530792342163\n",
      "16/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db3960cf384a447f9c619435fbb93242"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/20 5/4 F1 = 0.21680126880575737\n",
      "16/20 9/4 F1 = 0.13427092887501707\n",
      "16/20 16/4 F1 = 0.23311710438583924\n",
      "16/20 18/4 F1 = 0.195696639885233\n",
      "16/20 Best feature: 9 F1 = 0.22652384480371285 Worst feature: 16 F1 = 0.12767766929289068\n",
      "17/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97bbd93ecd1f45538ffffc6fe62d7c19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/20 5/3 F1 = 0.11842262031590867\n",
      "17/20 9/3 F1 = 0.0810325607042371\n",
      "17/20 18/3 F1 = 0.13565196498908993\n",
      "17/20 Best feature: 9 F1 = 0.27976221297449283 Worst feature: 18 F1 = 0.22514280868963998\n",
      "18/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "444c2f7f6fbe40a8b50af40f6e2ddab1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/20 5/2 F1 = 0.047141271727279\n",
      "18/20 9/2 F1 = 0.0\n",
      "18/20 Best feature: 9 F1 = 0.3607947736787299 Worst feature: 5 F1 = 0.3136535019514509\n",
      "19/20 Baseline F1 score: 0.3607947736787299\n"
     ]
    },
    {
     "data": {
      "text/plain": "Features:   0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d479ca4be80142d9994fb30003aaafda"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1138, in fit\n    X, y = self._validate_data(\n  File \"/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 918, in check_array\n    raise ValueError(\nValueError: Found array with 0 feature(s) (shape=(61928, 0)) while a minimum of 1 is required by LogisticRegression.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[176], line 39\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m feature \u001B[38;5;129;01min\u001B[39;00m eligible_features:\n\u001B[1;32m     37\u001B[0m     X_subset \u001B[38;5;241m=\u001B[39m X[:, [i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(features) \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m removed_features \u001B[38;5;241m+\u001B[39m [feature]]]\n\u001B[0;32m---> 39\u001B[0m     f1 \u001B[38;5;241m=\u001B[39m \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_subset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCV\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mf1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mmean()\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;66;03m#f1 = log.fit(X_subset, y).score(X_subset, y)\u001B[39;00m\n\u001B[1;32m     42\u001B[0m     f1_results[feature] \u001B[38;5;241m=\u001B[39m f1_iteration_baseline \u001B[38;5;241m-\u001B[39m f1\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:515\u001B[0m, in \u001B[0;36mcross_val_score\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[1;32m    513\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[0;32m--> 515\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:285\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[1;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[1;32m    266\u001B[0m results \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[1;32m    267\u001B[0m     delayed(_fit_and_score)(\n\u001B[1;32m    268\u001B[0m         clone(estimator),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m cv\u001B[38;5;241m.\u001B[39msplit(X, y, groups)\n\u001B[1;32m    283\u001B[0m )\n\u001B[0;32m--> 285\u001B[0m \u001B[43m_warn_or_raise_about_fit_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresults\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(scoring):\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:367\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[0;34m(results, error_score)\u001B[0m\n\u001B[1;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[1;32m    361\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    362\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    363\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    364\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    365\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    366\u001B[0m     )\n\u001B[0;32m--> 367\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[1;32m    369\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    370\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    371\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    372\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    376\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    377\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1138, in fit\n    X, y = self._validate_data(\n  File \"/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"/opt/homebrew/anaconda3/envs/edap01/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 918, in check_array\n    raise ValueError(\nValueError: Found array with 0 feature(s) (shape=(61928, 0)) while a minimum of 1 is required by LogisticRegression.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Backward elimination using F1 score as criterion\n",
    "\n",
    "CV = 5\n",
    "\n",
    "X = df.drop(['wl_time'], axis=1)\n",
    "X = X.iloc[:, :20]# Scale down X to only 10 features\n",
    "\n",
    "y = df['wl_time']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "log = LogisticRegression(max_iter=1000)\n",
    "\n",
    "features = X.shape[1]\n",
    "removed_features = []\n",
    "\n",
    "tracker = tqdm(total=features, desc=\"Iterations\")\n",
    "\n",
    "for iteration in range(features):\n",
    "    f1_iteration_baseline = cross_val_score(log, X, y, cv=CV, scoring=\"f1\").mean()\n",
    "    #f1_iteration_baseline = log.fit(X, y).score(X, y)\n",
    "    print(f\"{iteration}/{features}\", f\"Baseline F1 score: {f1_iteration_baseline}\")\n",
    "\n",
    "    f1_results = {}\n",
    "    eligible_features = [i for i in range(features) if i not in removed_features]\n",
    "\n",
    "    tracker2 = tqdm(total=features-iteration, desc=\"Features\")\n",
    "\n",
    "\n",
    "    for feature in eligible_features:\n",
    "        X_subset = X[:, [i for i in range(features) if i not in removed_features + [feature]]]\n",
    "\n",
    "        f1 = cross_val_score(log, X_subset, y, cv=CV, scoring=\"f1\").mean()\n",
    "        #f1 = log.fit(X_subset, y).score(X_subset, y)\n",
    "\n",
    "        f1_results[feature] = f1_iteration_baseline - f1\n",
    "        print(f\"{iteration}/{features}\",\n",
    "              f\"{feature}/{len(eligible_features)}\",\n",
    "              f\"F1 = {f1}\"\n",
    "              )\n",
    "        tracker2.update(1)\n",
    "\n",
    "\n",
    "        # 90 91 = -1 # BAD\n",
    "        # 90 89 = 1 # GOOD\n",
    "        # 90 90 = 0 # BAD\n",
    "\n",
    "    worst_feature = min(f1_results, key=f1_results.get)\n",
    "    best_feature = max(f1_results, key=f1_results.get)\n",
    "\n",
    "    if worst_feature == best_feature:\n",
    "        print(\"No feature to remove\")\n",
    "        break\n",
    "\n",
    "    print(f\"{iteration}/{features}\",\n",
    "          f\"Best feature: {best_feature} F1 = {f1_results[best_feature]}\",\n",
    "          f\"Worst feature: {worst_feature} F1 = {f1_results[worst_feature]}\",\n",
    "          )\n",
    "\n",
    "    removed_features.append(worst_feature)\n",
    "    tracker.update(1)\n",
    "\n",
    "print(\"ranking:\", removed_features)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop(['wl_time'], axis=1)\n",
    "y = df['wl_time']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "log = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Evaluate the model using all features and the F1 score metric\n",
    "print(\"Evaluating model with all features\")\n",
    "scores = cross_val_score(log, X, y, cv=5, scoring='f1_macro')\n",
    "avg_score = np.mean(scores)\n",
    "print(\"Initial F1 score:\", avg_score)\n",
    "\n",
    "# Iterate over all features and remove the one that has the smallest impact on the average F1 score\n",
    "n_features = X.shape[1]\n",
    "removed_features = []\n",
    "t_total_start = time()\n",
    "\n",
    "for i in range(n_features):\n",
    "    t_start = time()\n",
    "    print(\"Evaluating feature\", i, \"of\", n_features)\n",
    "    # Compute the F1 score for the current set of features\n",
    "    current_features = [j for j in range(n_features) if j not in removed_features + [i]]\n",
    "    X_subset = X[:, current_features]\n",
    "    scores_subset = cross_val_score(log, X_subset, y, cv=5, scoring='f1_macro')\n",
    "    avg_score_subset = np.mean(scores_subset)\n",
    "\n",
    "    # Compute the difference in F1 score between the current set of features and the original set of features\n",
    "    score_diff = avg_score - avg_score_subset\n",
    "\n",
    "    # Remove the feature that has the smallest impact on the F1 score\n",
    "    if score_diff > 0:\n",
    "        removed_features.append(i)\n",
    "        avg_score = avg_score_subset\n",
    "        print(\"Removed feature\", i, \"F1 score:\", avg_score)\n",
    "    t_stop = time()\n",
    "    t_elapsed = t_stop - t_start\n",
    "    t_left = (n_features - i - 1) * t_elapsed\n",
    "    print(\"Time elapsed:\", t_elapsed, \"Time left:\", t_left)\n",
    "    \"\"\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print removed features\n",
    "print(\"Removed features:\", removed_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
